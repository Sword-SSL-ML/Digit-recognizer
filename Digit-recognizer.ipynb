{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import keras\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Based on https://www.kaggle.com/poonaml/deep-neural-network-keras-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.read_csv('test.csv');\n",
    "train = pandas.read_csv('train.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape :  (42000, 784)\n",
      "y_train.shape :  (37800,)\n",
      "X_test.shape :  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\n",
    "print(\"X_train.shape : \",X_train.shape)\n",
    "Y_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "print(\"y_train.shape : \",y_train.shape)\n",
    "X_eval = test.values.astype('float32')\n",
    "print(\"X_test.shape : \",X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b6c21f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_rs = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "X_eval_rs = X_eval.reshape(X_eval.shape[0], 28, 28)\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train_rs[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.10, random_state=42)\n",
    "x_train_rs, x_val_rs = x_train.reshape(x_train.shape[0], 28, 28,1), x_val.reshape(x_val.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape (37800,)\n",
      "y_train.shape (37800, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "import random\n",
    "\n",
    "print(\"y_train.shape\",y_train.shape)\n",
    "y_train= to_categorical(y_train)\n",
    "y_val= to_categorical(y_val)\n",
    "print(\"y_train.shape\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train_rs.mean().astype(np.float32)\n",
    "std_px = X_train_rs.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "    return (x-mean_px)/std_px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import  Lambda , Dense, Flatten, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "#model.add(Flatten())\n",
    "model.add(Conv2D(filters = 10,kernel_size=(3,3),input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 300us/step - loss: 1.5575 - acc: 0.8523\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 11s 287us/step - loss: 1.9898 - acc: 0.8681\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 11s 290us/step - loss: 1.9599 - acc: 0.8738\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 11s 288us/step - loss: 1.9863 - acc: 0.8734\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 11s 288us/step - loss: 2.0795 - acc: 0.8689\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 11s 286us/step - loss: 1.9368 - acc: 0.8776\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 11s 286us/step - loss: 1.8085 - acc: 0.8863\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 11s 285us/step - loss: 1.9292 - acc: 0.8785\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 11s 286us/step - loss: 1.8989 - acc: 0.8810\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 11s 286us/step - loss: 1.8085 - acc: 0.8864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b7a36cb70>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_rs, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 1s 186us/step\n",
      "loss 1.8379085622514997\n",
      "acc 0.8842857142857142\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_val_rs, y_val)\n",
    "print(\"loss\",loss_and_metrics[0])\n",
    "print(\"acc\",loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense = Sequential()\n",
    "model_dense.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "model_dense.add(Flatten())\n",
    "model_dense.add(Dense(units=100, activation='tanh'))\n",
    "model_dense.add(Dropout(0.1))\n",
    "model_dense.add(Dense(units=10, activation='softmax'))\n",
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 3s 77us/step - loss: 0.3036 - acc: 0.9093\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.1662 - acc: 0.9502\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.1324 - acc: 0.9604\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.1096 - acc: 0.9671\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0949 - acc: 0.9715\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0857 - acc: 0.9742\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0768 - acc: 0.9763\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0701 - acc: 0.9786\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0645 - acc: 0.9797\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0608 - acc: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b7a9139b0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dense.fit(x_train_rs, y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 0s 65us/step\n",
      "loss 0.11138992428363834\n",
      "acc 0.9683333333333334\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model_dense.evaluate(x_val_rs, y_val)\n",
    "print(\"loss\",loss_and_metrics[0])\n",
    "print(\"acc\",loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
